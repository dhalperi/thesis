\ifx\mainfile\undefined
\input{chapter_head}
\setcounter{chapter}{5} % Set to n-1!
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Evaluating Effective SNR for MIMO-OFDM Channels}
\label{chap:delivery}

In this chapter, I experimentally evaluate how well my Effective SNR model predicts packet delivery for 802.11n wireless links. %This is the fundamental measure of whether the model can be useful; good predictions are necessary to solve link and network configuration problems.

To do so, I use my CSI measurement tool to gather a wide range of channel and performance information across 200 wireless links in both testbeds. This captures a wide variety of fading environments, from line-of-sight links in the same room to links between nodes in different rooms with RF barriers and reflectors spread around and between them. I use this data to evaluate the accuracy of predictions made using Packet SNR and Effective SNR.

The primary study in this chapter determines how accurately Effective SNR predicts whether packets will be delivered using different modulation and coding schemes. The goal is that for every modulation and coding scheme (MCS), a clear Effective SNR threshold separates those links that do not deliver packets at that rate from those that do, and thus that my model is accurate for practical links. Using these thresholds, I determine how well Effective SNR can identify the MCS with the highest throughput. I also compare how well Packet SNR works when used in the same way.

I next consider how well my model enables predictions about the effects of transmit power control on rate. This joint optimization problem highlights my model's flexibility. I conclude this chapter by evaluating the resilience of my Effective SNR system to interference, so that it can still be used to make predictions in contested wireless environments.

Combined, these three studies lay the foundation for showing that Effective SNR is accurate, flexible, and practical.

\section{Experimental Data}
I measured packet delivery over a 20\MHz channel on my two 802.11n testbeds, using links with four different antenna configurations:
\begin{enumerate}[parsep=1ex,itemsep=1ex,topsep=1ex]
\item The \textbf{SISO} configuration uses a single antenna at each node. This configuration corresponds to 802.11a.
\item The \textbf{SIMO} configuration uses a single transmit antenna but three receive antennas. This is an 802.11a/g/n configuration that uses spatial diversity techniques.
\item The \textbf{MIMO2} configuration uses two spatial streams and three receive antennas. This employs both 802.11n techniques of spatial multiplexing and spatial diversity.
\item The \textbf{MIMO3} configuration uses three antennas at each node to send and receive three spatial streams. This configuration uses spatial multiplexing but does not benefit from spatial diversity.
\end{enumerate}

For each of these configurations, I measured the packet delivery for each link using each MCS, at each transmit power level between $-$10\dBm and $+$16\dBm in steps of 2\dB. I sent 1,500-byte packets as constant bit-rate UDP traffic generated by \program{iperf} at 2\Mbps for 5 seconds, about 860 packets total. The receiver also recorded the CSI and per antenna RSSIs and noise floors to measure the RF channel for each correctly received packet. In these experiments, I turned off 802.11's link layer retransmissions in order to observe the underlying packet delivery rate. The experiments were conducted at night on unused 802.11 channels in order to minimize the effects of environmental movement and RF interference on these results.

%Note that CSI and RSSI are measured during the preamble, and so do not depend on the transmit rate, though they vary with the number of streams. 
%Similarly, 3x3 CSI gives us the channel between each pair of transmit and receive antennas, so it also implicitly contains 1x1 CSI.

The above tested across 200 links, 26\dB of transmit power, four antenna configurations ranging from SISO to MIMO3, and 8 MCS values per configuration. This covers all of the key variables needed to implement and evaluate my Effective SNR model.

\section{Packet Delivery with Effective SNR}
The first study in this chapter aims to understand whether Effective SNR is a good metric, i.e., whether it is an accurate predictor of packet delivery. In this section, I evaluate the model in three ways. The first is via the \define{transition window}, i.e., the SNR regime in which packet delivery for all links goes from near-zero to near-perfect. We saw in \chapref{chap:problem} that this transition occurs rapidly for a wired link (\figref{fig:snr_prr_attenuator}), but occurs over a wide range for wireless links (\figref{fig:snr_prr_26_65}) when using the Packet SNR. A narrow transition window that matches measurements of Packet SNR over a wire would be one indicator that Effective SNR works well.

The second evaluation metric is \define{rate confusion}, i.e., how many rates might be best at a particular SNR value. The example wired link showed clear separation between rates, such that at every SNR value there is a clear best rate. Conversely, because the transition regions of different wireless links overlap, links with the same Packet SNR might support very different rates. 

Finally, I determine the Effective SNR thresholds for each MCS and use them to predict the rate configuration with the \define{highest throughput} for each link. The accuracy of this prediction is a core measurement of how well my Effective SNR model can inform decisions.

For all of these analyses, I evaluate the predictions made by my Effective SNR model independently and as compared to Packet SNR.

\subsection{Transition Windows}
\label{sec:delivery_transition}
I begin with a visual comparison of the transition regions for real wireless links, and then present a quantitative evaluation of the difference between Packet SNR and Effective SNR in transition window width. I focus on SISO links, for which the most testbed links transition from being lossy to reliable. I examine the remaining configurations in the next section.

\subsubsection{Visual Comparison}
Recall \figref{fig:snr_prr_26_65} from \chapref{chap:problem}, which shows a scatterplot of packet reception rate (PRR) as a function of Packet SNR for three sample single-antenna modulations in the testbeds described in \chapref{chap:tool}. This graph demonstrated that for real wireless links, the width of the transition region is 10\dB or more, so that there is a large range of power levels for which Packet SNR does not predict performance.

In \figref{fig:snr_prr_siso}, I present a version of that plot that now includes data points for all eight modulation and coding scheme (MCS) combinations. In this graph, we can see that there is a correlation between Packet SNR and rate, but there is also a significant overlap between rates. For most MCS values, the transition region is at least five and often ten dB wide. For a large SNR range, many links will be lossy using one rate, while other links will work well at the next higher, or even the second higher, rate. This illustrates why Packet SNR computed from RSSI does not provide a good indicator of performance across testbed links in practice.

\begin{figure}[t!]
	\centering
	\includegraphics[width=\textwidth]{figures/delivery/snr_prr_scatter_siso.pdf}
	\caption[PRR vs SNR for all SISO modulations]{\label{fig:snr_prr_siso} A scatterplot of packet reception rate versus Packet SNR for wireless links in the testbed. There are wide transition regions and significant overlap between rates.}
\end{figure}
\begin{figure}[t!]
	\centering
	\includegraphics[width=\textwidth]{figures/delivery/esnr_prr_scatter_siso.pdf}
	\caption[PRR vs Effective SNR for all SISO modulations]{\label{fig:esnr_prr_siso}A scatterplot of PRR versus Effective SNR for the same wireless links. Relative to Packet SNR, there are narrower transition regions and cleaner separation between rates. The overlap that is present is generally between links that use the same modulation but different coding schemes (see \tabref{tab:siso_mcs}).}
\end{figure}

Contrast this with \figref{fig:esnr_prr_siso}, which shows the exact same set of data points but using Effective SNR instead of Packet SNR along the $x$-axis. This picture now shows a much clearer separation between rates. Especially for lower MCS values, only a few outlier links overlap with the next higher rate. Note also that, as shown in \chapref{chap:model}, the Effective SNR is several decibels lower than the Packet SNR because it measures the amount of power that is actually harnessed by the link, rather than the total power.

In both graphs the separation is generally larger between rates that use different modulations, e.g.\ between \mcs{2}, which uses QPSK, and \mcs{3}, which uses 16-QAM. In contrast, rates that only differ in coding rate overlap to a more substantial degree. This effect is worst for the highest rates (\mcs{5}--\mcs{7}), which use 64-QAM modulation. I believe this artifact is fundamental, as it matches the results from the wired link (\figref{fig:snr_prr_attenuator}); I attribute it to the fact that these three MCS use coding rates 2/3, 3/4, and 5/6 that are much closer together than the 1/2-coded and 3/4-coded combinations used for the QPSK and 16-QAM rates.

\subsubsection{Quantitative Evaluation}
The visual comparison presented above shows qualitatively that Effective SNR provides a more compact transition region and clearer separation between rates, but note that scatterplots can be misleading because they obscure density and distributions---each plot above has 16,188 points. To understand the data quantitatively, I analyzed the SISO measurements to find the transition window for each of the measured links.

\begin{table}
\centering
\begin{tabular}{cccccc}
\toprule
\multirow{2}{*}{MCS} & \multirow{2}{*}{Rate (Mbps)} & \multicolumn{2}{c}{$\Delta\rho_{\text{packet}}$ (dB)} &
\multicolumn{2}{c}{$\Delta\rho_{\text{eff}}$ (dB)} \\ 
\cmidrule(lr){3-4} \cmidrule(lr){5-6}
& &  ~~5\%--95\% & ~25\%--75\% & ~~5\%--95\% & ~25\%--75\%  \\
\midrule 
0 &  6.5                    & 3.08  & 1.29  & 2.05  & 0.81 \\
1 & 13.0                    & 3.45  & 1.44  & 2.38  & 0.89 \\
2 & 19.5                    & 6.27  & 3.12  & 2.30  & 0.85 \\
3 & 26.0                    & 3.93  & 1.98  & 3.02  & 0.94 \\
4 & 39.0                    & 7.05  & 3.49  & 2.19  & 0.93 \\
5 & 52.0                    & 7.16  & 3.20  & 2.29  & 1.06 \\
6 & 58.5                    & 7.25  & 3.37  & 2.92  & 1.41 \\
7 & 65.0                    & 7.24  & 2.81  & 2.92  & 1.35 \\
\midrule
\multicolumn{2}{c}{Average} & 5.68  & 2.59  & 2.51  & 1.03 \\         
\bottomrule
\end{tabular}
\caption[Width of SISO transition windows]{\label{tab:transitions} Width of SISO transition windows.}
\end{table}

Formally, I define the transition window of a particular rate to be the set of SNR values between which packet delivery rises from 10\% (lossy) to 90\% (reliable) for any link. \tabref{tab:transitions} gives the width of the transition window (denoted $\Delta\rho$) for SISO rates using the Packet SNR and Effective SNR metrics. I show the 25th--75th percentile range of points in the transition window as a measure of the typical link, and the 5th--95th range as a measure of most links. A good result here is a narrow 1\dB--2\dB window like that measured over a wire (\figref{fig:snr_prr_attenuator}).

The table shows that the transition widths are consistently tighter with my model than with Packet SNR. Most links transition within a window of around 2\dB for most rates. The width of the SNR-based transition windows is typically two to three times looser, especially for the denser modulation schemes like 64-QAM and higher code rates. At higher rates, it is easy for a sub-ideal channel to degrade packet reception. However, while the transitions for the last four rates are high with Packet SNR, they remain tight with Effective SNR.

\subsubsection{Limits on Accuracy}
In \tabref{tab:transitions}, the transition regions for Effective SNR range from 1\dB to about 3\dB, depending on the MCS value. In fact, these results for Effective SNR are about the best that can be obtained because they are close to textbook transitions for flat-fading channels and those measured over a wire (\figref{fig:snr_prr_attenuator}). A small improvement is surely possible, but this is probably limited by the precision of my measurement data. The IWL5300 gives RSSI, AGC and noise values in dB to the nearest integer, and outputs at most 8-bit CSI over a 48\dB range for only 30 out of 56 subcarriers. With this combination of factors, a CSI quantization error of at least 1\dB is likely.

\subsubsection{Summary}
This section showed that my Effective SNR model provides a channel metric that can narrow transition windows and a separation between rates. The larger significance of narrow transition windows is that, by reducing them enough that they do not overlap, I can unambiguously predict the highest rate that will work for nearly all links nearly all of the time. In contrast, Packet SNR transition windows overlap such that for a given SNR there may be many different best rates for different links in the testbed. I explore this next.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[p]
%	\begin{leftfullpage}
%	\centering
%	\subfigure[SISO configurations]{
%		\includegraphics[width=0.8\textwidth]{figures/delivery/siso_rate_confusion.pdf}%
%		\label{fig:snr_rate_step_1x1}%
%	}%
%	
%	\subfigure[SIMO configurations]{
%		\includegraphics[width=0.8\textwidth]{figures/delivery/simo_rate_confusion.pdf}%
%		\label{fig:snr_rate_step_1x3}%
%	}
%	\caption[Rate confusion with Packet SNR and Effective SNR for different antenna configurations]{\label{fig:snr_rate_steps}Rate confusion with Packet SNR and Effective SNR. Excepting very low and high SNRs, one Packet SNR value maps to multiple best rates for different links. For the same data, 
%Effective SNR provides a clear indicator of the best rate for nearly all links.}
%	\end{leftfullpage}
%\end{figure}
%
%\addtocounter{figure}{-1}
%\begin{figure}
%\begin{xtrafullpage}
%	\centering	
%	\setcounter{subfigure}{2}
%	\subfigure[MIMO2 configurations]{
%		\includegraphics[width=0.8\textwidth]{figures/delivery/mimo2_rate_confusion.pdf}%
%		\label{fig:snr_rate_step_2x3}%
%	}%
%
%	\subfigure[MIMO3 configurations]{
%		\includegraphics[width=0.8\textwidth]{figures/delivery/mimo3_rate_confusion.pdf}%
%		\label{fig:snr_rate_step_3x3}%
%	}
%	\vspace{36pt}
%\end{xtrafullpage}
%\end{figure}
%\addtocounter{figure}{1}

\subsection{Rate Confusion}
\label{sec:rate_confusion}

To understand whether my Effective SNR model accurately predicts packet delivery, I analyze the fastest working rate (PRR$\geq$ 90\%) for each link and all NIC settings. If we consider the set of all links that have the same SNR or SNR value (binned in groups of 1\dB), the \define{best link} is the link with the fastest working rate, and the \define{worst link} is the slowest. Ideally, SNR would perfectly indicate rate and all links with the same SNR would have the same best rate, but in practice there is a gap; this gap is the \define{rate confusion}.

In \figref{fig:snr_rate_steps}, I show the rate confusion by plotting the rate versus SNR for the best and worst links, broken down by configuration. Recall that to measure PRR I sent over 800 packets for each link in transmitter configuration. To assign a single Packet SNR or Effective SNR value to the trace, I choose the median measurement over all successfully received packets. The SISO experiment (\figref{fig:snr_rate_step_1x1}) shows links for both testbeds combined. The remaining graphs \figref{fig:snr_rate_step_1x3}--\ref{fig:snr_rate_step_3x3}  show rates for SIMO, MIMO2 and MIMO3 configurations for the Intel testbed only; it is denser than UW and supports MIMO experiments over the IWL5300's transmit power range. Note that the SIMO figure does not include data for the lowest 6.5\Mbps rate, because with the high degree of spatial diversity, very few links experience loss at that rate within the transmit power range of the IWL5300.

%Ideally, the best and worst lines would overlap completely, such that the highest rate for a given SNR would be the same for the best and worst links. This rate would then be an accurate prediction for the particular Effective SNR or Packet SNR level. Conversely, gaps between the best and worst lines expose confusion about which MCS will yield the highest performance for that SNR.

\begin{figure}[p]
	\centering
	\subfigure[SISO configurations]{
		\includegraphics[width=0.85\textwidth]{figures/delivery/siso_rate_confusion_lr.pdf}%
		\label{fig:snr_rate_step_1x1}%
	}%
	
	\subfigure[SIMO configurations]{
		\includegraphics[width=0.85\textwidth]{figures/delivery/simo_rate_confusion_lr.pdf}%
		\label{fig:snr_rate_step_1x3}%
	}%
	
	\subfigure[MIMO2 configurations]{
		\includegraphics[width=0.85\textwidth]{figures/delivery/mimo2_rate_confusion_lr.pdf}%
		\label{fig:snr_rate_step_2x3}%
	}%
	
	\subfigure[MIMO3 configurations]{
		\includegraphics[width=0.85\textwidth]{figures/delivery/mimo3_rate_confusion_lr.pdf}%
		\label{fig:snr_rate_step_3x3}%
	}
	\caption[Rate confusion with Packet SNR and Effective SNR for different antenna configurations]{\label{fig:snr_rate_steps}Rate confusion with Packet SNR and Effective SNR. Excepting very low and high SNRs, one Packet SNR value maps to multiple best rates for different links, though it works better in configurations that use spatial diversity (SIMO and MIMO2). For the same data, Effective SNR provides a clear indicator of the best rate for nearly all links.}
\end{figure}

For the SISO (\figref{fig:snr_rate_step_1x1}) and MIMO3 (\figref{fig:snr_rate_step_3x3}) cases, the figures show that using Packet SNR results in a large spread between the best and worst lines. Except for extremely low and high SNRs, nearly all SNRs have at least two---and up to five different---rates as suitable choices for the best rate. That is, Packet SNR often poorly indicates rate.

In sharp contrast, %looking at bottom lines in the graphs, 
the two Effective SNR lines overlap almost all the time, and mostly appear to be a single line. This is almost an ideal result. Effective SNR is a clear indicator of best rate. When there is slight separation, the spread is only between rates that use the same modulation but different amounts of coding, just as I described in the last section. These combinations are also close together in our wired experiments. 

Interestingly, these results show that Packet SNR predictions are much better for the SIMO and MIMO2 cases, though still not as accurate as Effective SNR, particularly for the highest rates. The reason is \emph{spatial diversity}: Spare receive antennas gather the received signal and combine it to make the channel more frequency-flat~\cite{Halperin_dummies}, thus bringing the Packet SNR closer to the Effective SNR. This effect is well-known, though typically not observable using real 802.11 NICs which, except my prototype implementation, do not export CSI. This result suggests that Packet SNR \emph{is} a reasonable predictor for an 802.11 configuration with significant diversity, using measured in that configuration. Still, Packet SNR does not transfer well across the antenna modes, because diversity gains and inter-stream interference change unpredictably. This makes Packet SNR less useful as a method of selecting rates, as we will see in the next section.

%Finally, I note that neither Effective SNR nor Packet SNR performs extremely well at the lowest modulation at low SNRs. I believe this artifact arises from errors in the AGC values reported by the NIC, observed by Judd et al.~\cite{Judd_CHARM} and confirmed by my data for Intel's hardware.

\subsection{Selecting Rates}
In \secref{sec:delivery_transition}, I showed that transition regions for Effective SNR are generally tighter than for Packet SNR. In \secref{sec:rate_confusion} I showed that Effective SNR as a channel measure has less rate confusion relative to Packet SNR. These results indicate that a threshold-based Effective SNR algorithm should be better able to distinguish whether a particular MCS combination works for most links. In this section, I show how to choose SNR thresholds and analyze whether these thresholds lead to good choices for real wireless links in my testbeds.

\subsubsection{Choosing SNR Thresholds}
The first question is how we should choose the SNR thresholds needed in \eqref{eq:threshold} to decide whether a link will reliably deliver packets in a particular configuration. A low SNR threshold will lead to aggressive rate selection, with many \define{false positives} as transmitters sending at a rate faster than the link supports, and widespread packet loss. A high SNR threshold will cause many \define{false negatives}, in which transmitters select rates conservatively and send more slowly than necessary. In this thesis, I use a simple heuristic: Choose thresholds to balance the prevalence of false positives and false negatives.

To find the threshold for a particular MCS value, I use the following procedure. Define \define{good links} to be those links with PRR $\geq$$90\%$. The CDF of the SNR values for these links then indicates the false negative rate; choosing the 25th percentile SNR as the threshold means that the 25\% of links that have lower SNR values will be falsely classified as not working. Similarly, we can define \define{bad links} to be those with PRR $<$$80\%$. Then the CDF of the SNR values for these links shows the inverse of the false negative rate; the 25th percentile SNR would falsely classify the 75\% of links with larger SNR values as good links. To balance false negatives and false positives, we can plot the CDF of SNR values for good links and the complementary CDF of SNR values for bad links on the same graph. The $x$-coordinate of the intersection point of the two lines is the SNR threshold that balances false positive and false negative errors rates, and the $y$-coordinate of that point gives the \define{balanced error rate}. An ideal result is a balanced error rate of 0\%, so that the SNR threshold perfectly classifies all links as working or not.

\begin{figure}[p]
	\begin{leftfullpage}
	\centering
	
	\begin{tabular}{cccc}
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_0.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_1.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_2.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_3.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_4.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_5.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_6.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_7.pdf} \\

	\midrule
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_8.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_9.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_10.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_11.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_12.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_13.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_14.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_15.pdf} \\

	\midrule
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_16.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_17.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_18.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_19.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_20.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_21.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_22.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/packet_snr_goodbad_23.pdf}
	\end{tabular}

	\caption[Thresholds and False Negative/Positive Rates with Packet SNR]{\label{fig:packet_snr_goodbad}False negative and false positive error rates as a function of Packet SNR threshold. The figure shows results for wireless links that use one- (\emph{top}), two- (\emph{middle}), and three-stream (\emph{bottom}) rates (\mcs{0}--\mcs{23}).}
	\end{leftfullpage}
\end{figure}

\begin{figure}[p]
	\begin{xtrafullpage}
	\centering
	\begin{tabular}{cccc}
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_0.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_1.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_2.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_3.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_4.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_5.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_6.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_7.pdf} \\

	\midrule
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_8.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_9.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_10.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_11.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_12.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_13.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_14.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_15.pdf} \\

	\midrule
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_16.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_17.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_18.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_19.pdf} \\
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_20.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_21.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_22.pdf} &
	\includegraphics[height=1.2in]{figures/delivery/goodbad/esnr_goodbad_23.pdf}
	\end{tabular}

	\caption[Thresholds and False Negative/Positive Rates with Effective SNR]{\label{fig:esnr_goodbad}False negative and false positive error rates as a function of Effective SNR threshold. The figure shows results for wireless links that use one- (\emph{top}), two- (\emph{middle}), and three-stream (\emph{bottom}) rates (\mcs{0}--\mcs{23}).}
	\end{xtrafullpage}
\end{figure}

\begin{figure}[htbp]
  \begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{figures/delivery/goodbad/error_rates.pdf}
  \caption[Balanced error rates for Effective SNR and Packet SNR]{Balanced error rates for Effective SNR and Packet SNR in wireless testbed links.}
  \label{fig:balanced_error}
  \end{minipage}
  \hfill
  \begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{figures/delivery/goodbad/error_ratio.pdf}
  \caption[Balanced error rate for Effective SNR relative to Packet SNR]{The balanced error rate for Effective SNR relative to Packet SNR in wireless testbed links.}
  \label{fig:balanced_error_ratio}
  \end{minipage}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/delivery/goodbad/selection_performance.pdf}
  \caption[Performance from selecting rates with Effective SNR and Packet SNR]{The performance of selecting rates based on Effective SNR and Packet SNR thresholds for 2163 wireless testbed links.}
  \label{fig:selection_performance}
\end{figure}


\figref{fig:packet_snr_goodbad} shows the error rate versus Packet SNR for the SIMO, MIMO2, and MIMO3 configurations, and \figref{fig:esnr_goodbad} shows the same data using Effective SNR. Unlike in \secref{sec:rate_confusion}, the Packet SNR or Effective SNR value used to make these graphs is taken from a single MIMO3 packet. To compute Effective SNR for SIMO and MIMO2 configurations, I compute the SIMO and MIMO2 Effective CSI as described in \chapref{chap:model}. For Packet SNR, I use the measured Packet SNR for all antenna configurations, as the transmitter keeps the total radiated power constant across antenna modes.

The results show that both SNR values have a balanced error rate under 14\% for all configurations. Effective SNR has a lower error rate for all but the lower MIMO2 rates, often much lower. We also see that both schemes perform worst for the highest MCS combinations in each antenna mode that use 64-QAM with close coding rates. This matches the expectations from earlier sections.

I plot the CDF of the balanced error rate for each scheme in \figref{fig:balanced_error}. The balanced error rate curve is generally 1\%--2\% less for Effective SNR than for Packet SNR. I also plot the relative balanced error rate of Effective SNR compared to Packet SNR in \figref{fig:balanced_error_ratio}. This graph shows that the Effective SNR balanced error rate is as low as 40\% of that achieved with Packet SNR, and less than 10\% worse for the single rate where that is the case. Thus, it seems likely that my threshold-based Effective SNR model will be a better predictor of link performance than using thresholds with Packet SNR. I investigate this next.

\subsubsection{Using Thresholds to Select Rates}
Having computed the Packet SNR and Effective SNR thresholds for each MCS value, I now evaluate how well the chosen rates work in my testbed.

I used the thresholds computed above to choose rates for 2163 links in my wireless testbed. These are the links that support at least 6.5\Mbps, so they can deliver packets, but are not so strong that the fastest rate works perfectly, so that rate selection is meaningful. I follow the procedure in \algref{alg:eff_snr_basic}: Given a single Packet SNR or Effective SNR measurement from each trace, identify the set of working configurations and then choose the fastest one. Given a choice of rate, I use the ground truth data described earlier to compute the actual performance of that rate for these testbed links, relative to the performance of the optimal choice.

\figref{fig:selection_performance} shows the results when selecting rates using Packet SNR or Effective SNR. The graph contains one line for each algorithm. A point $(x,y)$ on a line means that the corresponding algorithms achieves at least an $x$ fraction of optimal performance for a $y$ fraction of links. An ideal result would be a vertical line $x=1$, showing that all links achieve optimal performance.

In this graph, we see that Effective SNR dramatically outperforms Packet SNR. The median link in our testbed achieves 83\% of optimal performance using rates selected with Effective SNR, while using Packet SNR for rate selection results in a median performance of 13\%. With Packet SNR, nearly half the links choose rates that deliver no packets at all, while Effective SNR is so excessively aggressive for less than 10\%. Though there is still a sizable gap from optimal, this experiment highlights that Effective SNR performs much better than the Packet SNR, even when using only a single channel measurement and no adaptation of rates. (I explore rate adaptation in detail the next chapter.)

To understand how much the particular choice of threshold affects both algorithm, I experimented with raising or lowering the SNR thresholds uniformly across the different MCS choices. Raising the Effective SNR thresholds by 1\dB results in more conservative choices of rate and improved average performance: Fewer links achieve maximum performance, but the worst links that were over-selecting improve to a larger fraction of optimal. However, raising or lowering the Packet SNR had little effect on the curves in \figref{fig:selection_performance}, which suggests that the balanced error rate technique achieves locally-optimal thresholds.

Why does Effective SNR choose rates so much better than Packet SNR? The key reason is that Effective SNR is able to compute a different Effective CSI for each modulation and number of spatial streams based on the particular subchannels used. This means that Effective SNR can make decisions about each configuration independently, and hence can recognize when fading will make a strong link work poorly in one antenna mode but not another. In contrast, there is no way using RSSI measurements alone to predict Packet SNR in different configurations. Packet SNR must make a decision independent of fading, which often results in overly-aggressive choices.

This dramatic difference in performance highlights the key strength of Effective SNR: Its ability to predict performance in a wide space. Though this example only included selecting rates keeping all other metrics fixed, subsequent studies will consider additional dimensions of the wireless configuration space.

\subsection{Summary}
In this section, I analyzed whether Effective SNR accurately predicts packet delivery. I found that viewing wireless links through the lens of Effective SNR can lead to visual separation between rates and narrow transition regions within rates. The second part of this study showed that Effective SNR is a clear indicator of rate, usually narrowing down the possible set of best rates to one or two MCS within an antenna configuration. The third analysis showed that Effective SNR results in generally good choices for rate (median 83\% of optimal), while Packet SNR often chose rates that simply did not work (median 10\% of optimal).

In the rest of this chapter I demonstrate that Effective SNR has a few other useful properties that other channel metrics do not, namely that it can be used to solve joint optimization problems such as between transmit power and rate, and that the estimates it provides are robust to interference.

\section{Transmit Power Control}
\label{sec:tx_power_trim}
The data above showed that my Effective SNR model can predict delivery for measurements taken over a range of transmit powers, among other choices of rate and spatial streams. I now show apply this model to the \emph{joint interaction} of transmit power and rate, and I show that CSI measured at one transmit power level is useful to predict delivery at a \emph{different power level}. This is valuable for power control applications, e.g., pruning excess power to reduce co-channel interference. Earlier work has shown that Packet SNR based on RSSI does not do this well~\cite{Monks_PowerMAC,Ramachandran_Symphony,Son_PowerStudy}. 

\subsection{Transmit Power Control in Faded Channels}
First, I analyze the effect of changing transmit power in faded channels. To do this, I simply scale the CSI measured at maximum transmit power for a link and compute the resulting Effective SNR over a range of power levels.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/delivery/eff_vs_snr_qpsk.pdf}
  \caption[Effective SNR vs Packet SNR for four faded links]{Effective SNR (for QPSK) versus Packet SNR for flat (left) to faded (right) links.}
  \label{fig:eff_vs_rssi}
\end{figure}

I found that changing transmit power has a different effect (in terms of delivery and highest rate) on different testbed links even if they start at exactly the same rate and SNR value. \figref{fig:eff_vs_rssi} plots the Effective SNR versus Packet SNR relationship for six example SISO links from my 802.11n testbeds, chosen to represent a range of frequency-selective fading profiles similar to those in \figref{fig:example_fsf_shape}. The links range from nearly flat to deeply faded. Correspondingly, they have different slopes.

On the left, Packet SNR matches Effective SNR for the nearly flat link. Since all subcarriers have the same strength, this link can be modeled as a single carrier with a single BER, and hence scaling transmit power has a linear effect on the Effective SNR. However, for the right-most, deeply faded links, the Packet SNR decreases from 25\dB to 15\dB (10$\times$ transmit power reduction) between the dashed lines, while the Effective SNR only drops by 4\dB (2.5$\times$). This occurs because reducing the power has different effects on error rate at different SNR levels (see \figref{fig:mod_ber_snr})---so additional power has less impact on strong subcarriers than on weak subcarriers. This difference in how well devices harness power across links makes transmit power control non-trivial and explains why it has been hard for prior algorithms to use measurements at one SNR value to predict how well links will work at a different power level.

\subsection{Making Predictions with Effective SNR}
I test the ability of Effective SNR to make predictions across power levels by considering the goal of trimming excess transmit power. Excess transmit power is power that can be removed without causing the highest rate for the link to drop.

These experiments start with 88 SISO links from the Intel Labs Testbed configured to radiate 10\mW of transmit power. I then take a single CSI sample per link. Considering transmit power reductions in increments of 2\dB, I use the threshold-based Effective SNR and Packet SNR algorithms to predict the best supported rate for each reduced power level, and choose the lowest power level with the same best rate. The measurements described earlier include the ground truth packet reception rate for each power level and thus these they can be used to check the accuracy of the predictions.

\begin{figure}[t]
      \centering
      \subfigure[Predicted and measured power saving]{%
      \includegraphics[width=0.5\columnwidth,viewport=0 7 195 110,clip]{figures/delivery/power_save_1x1.pdf}%
      \label{fig:power_save_cdf}%
      }%
      \subfigure[Measured PRR corresponding to reduced TX power levels]{%
      \includegraphics[width=0.5\columnwidth,viewport=0 7 195 110,clip]{figures/delivery/power_save_final_prr_1x1.pdf}%
      \label{fig:power_prr_cdf}%
      }%
      \caption[Impact of pruning excess transmit power]{\label{fig:power_save_1x1} Power saving and performance impact of pruning excess transmit power. Pruning with Effective SNR is tight (within 0.5\dB) and does not degrade performance. Pruning with packet SNR degrades performance more without much extra savings.} 
\end{figure}


\figref{fig:power_save_1x1} shows the power savings and performance degradation of four different threshold schemes. A good result here is power savings without a loss of performance; the absolute amount of power savings is not meaningful as it depends on the testbed and the link. The Measured (Optimal) line shows the best that can be done. Measured PRRs at all power levels are used to guide power control decisions. Therefore, the final delivery probabilities are hardly decreased (all links have PRR$\geq$90\%). Most links save a little power, and some save a lot.

The graphs show that using Effective SNR to predict how much power to trim has a similarly good tradeoff. Impact on rate remains limited, yet power is saved, more than 10\dB for around 10\% of the links. The gap between the Measured and the Eff SNR lines is because Eff SNR thresholds might be slightly conservative for some links.

To show that this trimming is tight, I considered the effect of using more aggressive---i.e. slightly lower (0.5\dB)---Effective SNR thresholds. This operation results in little additional power savings, but degrades performance for many more links.

Finally, I compared this algorithm to a scheme that uses Packet SNR to save power. The results show Packet SNR the savings are roughly similar, but more links have degraded performance and several stop working altogether.

%\xxx{@Dan: Redo these graphs}

\section{Interference}
\label{sec:interference}
I conclude this chapter by investigating how my Effective SNR-based model can cope with interference. This challenge is one of the largest potential weaknesses of this technique, because Effective SNR is based on measurements taken only during the packet preamble. There are three important components of dealing with interference, which I approach in turn.

\subsection{CSI During Interference}
The first question is: If a weak interferer occasionally transmits while a packet is being received, does this weak transmission cause wild swings in the predicted link quality?

I studied the variation of CSI measurements during transient interference. I chose two nodes at UW that do not detect each other with carrier sense, and alternately designated one as the transmitter and the other as the interferer. The nodes were configured to send large packets designed to collide, while all other receiving nodes monitored the CSI to simulate a total of 20 links. The experiment also varied the transmit power of the node designated as the interferer from low to high to induce a large range of interfering channels, over which I evaluate the impact of interference on CSI measurements and my Effective SNR model.

For all but one of 20 links, the rate predicted by my model for the majority of correct packets was the same with and without interference; the remaining link was off by a single rate. In other words, the interference does not corrupt the CSI measurements, because the MIMO-OFDM training procedure can fairly accurately estimate CSI. Note that OFDM does not turn interference into inflated RSSI, unlike the spread spectrum modulations used in 802.11b. From these measurements, we can conclude that the mere presence of interference does not completely invalidate Effective SNR values, and thus transient interference will not necessarily cause wild swings in the recommend transmit configuration.

\subsection{Recognizing Collisions}
A second task is to recognize collisions when they occur, in order to distinguish between too-aggressive rate selection and interference loss. The solutions to these problems are very different. To work around persistent collisions from hidden terminals, a transmitter increases its MAC backoff counter and/or initiates the RTS/CTS procedure which is normally disabled for protocol efficiency. In contrast, when rates are over-selected the transmitter should reduce its rate but ideally need not add additional protocol delay. Accurately distinguishing between these two effects is known to improve performance in practice~\cite{Wong_RRAA,Jamieson_PPR,Vutukuru_SoftRate}.

To recognize collisions, I propose to leverage a new MAC feature of the 802.11n packet aggregation mechanism. Block ACKs selectively acknowledge frames in a batch of packets transmitted as one continuous burst. Each packet in the burst has a separate checksum, and thus the Block ACK serves as block-based feedback of packet correctness just like the block-based checksums analyzed in PPR~\cite{Jamieson_PPR}. We can therefore use the error patterns in the Block ACK to recognize collisions: When the rate is over-selected, errors should be randomly distributed throughout the batch, and bursty when a collision clobbers a continuous part of the batch. The ability to recognize interference and hence decouple interference avoidance and rate selection has been shown to improve performance in many systems (e.g., SoftRate~\cite{Vutukuru_SoftRate}).

\subsection{Effective SINR}
The final task is to dealing with persistent interference, i.e., if the RTS/CTS procedure does not successfully avoid collisions. For continuous interference the Effective SNR computed from CSI will likely provide an aggressive estimate, and the system will need another way to compensate. It may be possible to use an \define{Effective Signal-to-Interference-and-Noise Ratio (Effective SINR)} metric that incorporates CSI measurements from the interfering nodes to predict packet delivery taking into account the MIMO-OFDM fading properties of both the desired signal and any interfering transmissions. I leave the investigation of this technique to future work.

%Because it does not use packet loss as a signal, ESNR will not conservatively reduce rate during interference. Thus transient interference will only cause transient interruptions. However, the Effective SNR measured in a single packet preamble simply does not provide an estimate of link quality when the link experiences persistent interference. One solution is to leverage SoftRate in these circumstances; while Effective SNR can guide the overall choice of antennas and number of spatial streams, SoftRate's continuous estimate of BER may be better suited for choosing rates within one mode. An alternative (that we have not yet explored) might be an \emph{Effective SINR} metric incorporating CSI measurements from the interfering nodes to predict packet delivery.

\section{Summary}
From the studies in this chapter, I conclude that Effective SNR consistently provides accurate estimates of packet delivery for nearly all links and all configurations without any per-link calibration. Viewing diverse wireless links in my testbeds through the lens of Effective SNR showed that there is a low degree of rate confusion and narrow transition region, contrary to the same results with Packet SNR. I presented my method to choose Effective SNR thresholds, and showed that Effective SNR can select rates that work well for most testbed links. The results in \secref{sec:tx_power_trim} demonstrate the flexibility of this approach by showing that CSI measurements are valid not just across different rates, but also across transmit power scaling. Finally, I discussed three ways in which my Effective SNR model, in conjunction with 802.11n protocol features, can work well in the presence of interference, though I leave detailed investigation of this problem for future research.
% that Effective SNR measurements are generally not corrupted by transient interference, as long as the packet preamble from which CSI is measured is relatively interference-free.

In the remainder of this thesis I evaluate the ability of Effective SNR to solve a variety of tasks. In the next chapter, I deploy my model as part of a rate adaptation system that selects the operating rate for a wireless link in mobile channels.

%From now on, we use the thresholds in these graphs to predict the working rate for any link. They agree with the measured SNRs on a wired link (\figref{fig:snr_prr_attenuator}), which strongly suggests that the Effective SNR captures the fundamental error characteristics of the link. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ifx\mainfile\undefined
\input{chapter_tail}
\fi
