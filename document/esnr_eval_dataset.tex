\section{Experimental Methodology}
To understand how well different techniques perform at the applications studied in this chapter, I took comprehensive measurements of both packet delivery and the RF channel in the University of Washington testbed. These data provide the actual ground-truth performance of links in different configurations and also a record of the channel state during the experiments. Using this data, I perform offline simulations of the different algorithms.

\subsection{Dataset}
I measured the links between 24 static devices in my testbed at the University of Washington. The measurements in this chapter were taken 3 years after the measurements used in \chapref{chap:delivery} and \chapref{chap:rate}, and include a different set of devices. In addition to evaluating the applications in question, the results in this chapter will also tell us whether these NICs in practice experience physical degradation that invalidates their in-factory calibration.

I took measurements on all 35 channels, each 20\MHz wide, that the IWL5300 devices support. Of these 35 channels, 11 overlap in the 83\MHz-wide unlicensed 2.4\GHz band, and the remaining 24 non-overlapping channels are spread across three non-contiguous bands between 5.170\GHz and 5.835\GHz. In an experiment, one sender transmits packets with random payloads to 23 receivers. The transmitter sends a total of 2400 packets by interleaving 100 packets from each of the 24 MCS that correspond to 1-, 2-, or 3-stream 802.11n rates. Each receiver uses 3 antennas for spatial diversity and/or spatial multiplexing. I cycled through all transmitters and all channels over the course of a few hours, and took data at night to attempt to minimize the impact of interference.

\subsection{Computing Ground Truth Packet Delivery}
The above measurements included 100 packets for each link, MCS, and channel. From these data, it is straightforward to compute the ground-truth packet reception ratio (PRR) for each of these configurations. Then for each link $\ell$, I compute the Performance ($P$) of that link at each MCS ($m$):
\begin{equation}
	\label{eq:prr_throughput}
	P_{\ell,m} = \frac{R_{\ell,m}}{100} \cdot B(m),
\end{equation}
where $B(m)$ is the raw bitrate of \mcs{$m$}. Note that while this estimate of performance does not take into account MAC-layer effects, the use of packet aggregation in 802.11n means this is a reasonable proxy.

In this chapter, I decouple the ability to make accurate choices at the application-level from the rate selection algorithm needed to realize it. I thus assume an ideal rate selection algorithm that always correctly chooses the fastest MCS:
\begin{equation}
	\label{eq:best_throughput}
	P_\ell = \max_m P_{\ell,m}.
\end{equation}
These data to provide an Optimal baseline against which I compare Packet SNR- and Effective SNR-based application configuration algorithms.

\subsection{Simulating RF Measurement-based Algorihtms}
While measuring the ground truth performance of the link, I sent exhaustive packet probes at all rates, and collected the RSSI and CSI for each correctly received packet. Of course, this collected information would not be available to an algorithm attempting to quickly assess a channel's performance with RF measurements. Instead, these algorithms are given only the RF measurements from the first packet received in order to compute Packet SNR ($\rho$) and Effective SNR ($\rho_\text{eff}$). By using only the first measurement, I emulate the performance that a configuration algorithm would obtain in practice, where it uses only a single probe.

In the next three sections, I use these data to evaluate how well my Effective SNR model can make access point, channel, and path selections in practice. I use a mobile dataset for the last subsection, and describe it therein.