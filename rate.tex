\ifx\mainfile\undefined
\input{chapter_head}
\setcounter{chapter}{6} % Set to n-1!
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Application to Rate Selection}
\label{chap:rate}

The most direct uses of packet delivery predictions are rate adaption, transmit power control, and channel selection. Each of these is a well-studied topic. As an example application, we study how our model can inform rate adaptation. We first use trace-driven simulation to compare against the state-of-the-art rate adaptation schemes for 802.11a/g over a range of channels. They provide a well-established baseline against which we can gauge our performance. Our goal is to perform as well as the best, already near-optimal 802.11a/g schemes on their home ground, with a method that has the advantages of simplicity, deployability, and generality.

Next, we show that our method extends well to 802.11n (MIMO) and so provides ongoing value. Rate adaptation is an open problem for 802.11n. Most schemes in the literature were not designed for MIMO systems, and none of the ones that were have been tested on real 802.11 channels.\footnote{The only experimental evaluation of MIMO rate adaptation we know of is on Hydra~\cite{Kim_Hydra}. It uses the USRP radios for 2\MHz channels that are relatively narrowband and flat.} 

\section{Rate Selection Algorithms}
We experiment with ESNR, an algorithm based on our model, plus SampleRate~\cite{Bicket_SampleRate}, the de facto rate selection algorithm in use today, and SoftRate~\cite{Vutukuru_SoftRate}, a research algorithm with the best published results.

\textbf{SampleRate}~\cite{Bicket_SampleRate} is an implicit feedback scheme that uses only information about packet reception or loss.
It maintains delivery statistics for different rates to compute the expected airtime to send a packet, including retries.
It falls back to a lower rate when the airtime of the chosen rate exceeds (due to losses) the airtime of a lower rate.
Standard implementations send a packet to probe 1 or 2 higher rates every 10 packets, to determine whether to switch to higher rates.

The main weakness of SampleRate is its slow reaction to change. If the wireless channel quickly degenerates, SampleRate will incur multiple losses while it falls back through intermediate rates.\footnote{The original SampleRate~\cite{Bicket_SampleRate} did not reduce rate for retries, but some implementations~\cite{Judd_CHARM} and the version used in modern kernels~\cite{Minstrel} do. This turns out to be important for good performance.} When the channel suddenly recovers, SampleRate's infrequent probing converges to the new highest rate slowly. Algorithms such as 
RRAA~\cite{Wong_RRAA} aim to improve on SampleRate's weaknesses, but as they are less widely used we stick with SampleRate as a representative probe-based algorithm.

SampleRate is only defined for SISO links. MIMO breaks some of its assumptions, as higher rates can work when lower ones do not due to different antenna modes. Thus, we only compare it for 802.11a/g experiments. 

\textbf{SoftRate}~\cite{Vutukuru_SoftRate} is an explicit feedback scheme that uses information gleaned during packet reception at a given rate to predict how well different rates will work. The input to these predictions is the bit error rate (BER) as estimated from side-information provided by the convolutional decoder. SoftRate chooses rates based on the performance curves that relate the BERs for one rate (a combination of modulation and coding) to another. %the BER for a different modulation and coding. 
Each rate will be the best choice only during a predictable BER range. These predictions can help SoftRate quickly identify the best rate. SoftRate has been shown to dominate trained SNR-based algorithms such as CHARM~\cite{Judd_CHARM} and we do not evaluate against those directly.

%SoftRate drops rate on retries to ensure that packets are delivered.

SoftRate is defined for SISO channels, like SampleRate, 
and its predictions hold only for fixed transmit power and antenna modes, so it does not extend to MIMO systems.
We only compare it for 802.11a/g experiments. 
To cover the full SISO range, we extended the MIT implementation of SoftRate to QAM-64 and 2/3 and 5/6 rate codes.

\textbf{ESNR} uses our model in a very simple way: given recent channel state information, compute the highest rate configuration that is predicted to successfully deliver packets (PRR $>90\%$). It runs at the receiver, measuring CSI on received packets and returning rate changes to the sender along with the ACK like SoftRate. Finally, to protect against poor choices near a rate boundary in our model, we fall back one rate if consecutive packets must be retried and the effective SNR level has not changed. This is a fixed rule.

Like SoftRate, our algorithm obviates the search phase. There is no calibration of dynamic thresholds. This is not rate \emph{adaptation} so much as rate \emph{selection} that changes only because it tracks the channel's evolution. And unlike SoftRate, the predictions of our model hold over different antenna modes. This lets us run over 802.11n rates as easily and in the same way that we run over 802.11a/g rates. Thus, we report results from both 802.11a/g and 802.11n runs for our algorithm.

\textbf{Optimal.} We also take advantage of simulation to add upper bounds on achievable performance. This lets us assess how well the algorithms perform on an absolute scale. The OPT scheme has an oracle that knows the true highest rate that can be successfully delivered at any given time. The Previous-OPT scheme knows the optimal rate that worked on the channel for the previous packet and uses it for the next transmission; it just does not know the future. Since SoftRate and ESNR use an estimate of this previous channel state, and SampleRate infers the recent channel state, they are unlikely to beat Previous-OPT\@. The gap between Previous-OPT and OPT is also likely to be significant because of inherent wireless channel variability.
%OPT gets the benefit of transient improvements and faster rates with low, but non-zero delivery probability for free.


\section{Trace-driven Simulator}

%We use a simulator to compare these algorithms running on the same channel. Our ESNR algorithm runs in real time on a mobile client with the Intel 802.11 NIC\@. However, we turn to simulation for two reasons. First, SoftRate runs on a software-defined radio, not a commercial NIC, so we need to use simulation to compare the two. Second, good algorithms have consistently good performance over a range of channels. For example, no algorithm will beat SampleRate by a significant margin on static channels because it will quickly adapt to the channel. However, algorithms like SoftRate perform well even when the channel is changing rapidly due to mobility. With a simulator, we can compare algorithms over this range of conditions. 

Although our ESNR algorithm runs in real time on a mobile client with the Intel 802.11 NIC,\footnote{We implemented a version of ESNR that randomly probes other antenna modes to collect CSI and that also sends effective SNR estimates back to the transmitter, and ran it online against SampleRate in human-scale mobility. We found that the probing and feedback have little penalty, and our results match the simulator: the two algorithms are separated by a small (5--10\%) margin.} we turn to simulations to compare these algorithms. %running on the same channel. 
This is for two reasons. First, SoftRate runs on a software-defined radio, and cannot be implemented on a currently available commercial NIC\@. Second, we want to compare the algorithms over varied channel conditions, from static to rapidly changing, to assess how consistently they perform. 
For example, no algorithm will beat SampleRate by a significant margin on static channels, because it will quickly adapt to the channel. In contrast, SoftRate performs well even when the channel is changing rapidly due to mobility. However, it is hard to generate controllable high-mobility experimental settings. 


%The simulator we build is trace-driven. 

\heading{Trace.} We collect real channel information for the simulations. A mobile client in T1 that is moved at normal walking speed sends short, back-to-back packets to stationary testbed nodes that record the CSI\@. The CSI reflects frequency-selective fading over real, varying 20\MHz MIMO channels that is typically not observed with more narrowband experimentation, e.g., on the USRP\@. Note that CSI is estimated during the preamble of the packet transmission, independent of the modulation and coding of the payload. Therefore, the mobile transmitter can quickly cycle through all antenna configurations (1x3, 2x3 and 3x3) by sending a single short UDP packet at the lowest rate for each configuration. This enables fine grained sampling of the channel every 650\us. The following results are derived from a trace with approximately 85,000 channel measurements taken over 55 seconds, spanning varying RF channels that range from the best 3-stream rates to SISO speeds.

\heading{Simulator.} We feed this trace to a custom 802.11a/g/n simulator written in a combination of MATLAB and the MIT C++ GNU Radio code. The simulator implements packet reception as shown in \figref{fig:ofdm_decoding}, including demodulation for BPSK through QAM-64, deinterleaving, and convolutional decoding with soft inputs and soft outputs. The measured CSI is interpolated to 56 carriers and serves as the ground truth for the channel, and packets are correctly received when there are no bit errors, or are lost. SampleRate, SoftRate, and ESNR are implemented as described previously. To ensure that ESNR is not given the unrealistic advantage of ground truth CSI, we corrupt the CSI at the level of ADC quantization, which typically induces an error of $\pm$1.5\dB in the output effective SNRs. SoftRate estimates the BER directly during decoding.

To vary mobility, we replay the trace at different speeds. For example, 4$\times$ mobility gives ESNR the CSI from every fourth trace record. However, packet reception still uses all trace records. For a packet to be correctly received in the accelerated trace, it must be received over the intermediate records. We require correct reception at $\geq$80\% of the records to allow for coding. This models a varying channel that we can only sample for CSI periodically, as happens when CSI is measured during the packet preamble. SoftRate operates using the 80$^\text{th}$ percentile soft estimate from the range.

We aim to evaluate the ability of these algorithms to respond to changing channel conditions. Thus, our primary metric is the delivered PHY layer rate per trace index. Higher-layer factors such as MAC backoff, link-layer packet aggregation, and TCP reactions to loss, will affect how this rate translates to throughput.

\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=120 68 491 760,clip,width=0.95\columnwidth]{figures/esnr/siso_rate_time_opt_eff.pdf}
      \caption{\label{fig:siso_rate_time_opt_eff} OPT and ESNR SISO performance in human-speed mobility.}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=120 68 491 760,clip,width=0.95\columnwidth]{figures/esnr/siso_rate_skip_opt_eff.pdf}
      \caption{\label{fig:siso_rate_skip_opt_eff} OPT and ESNR SISO performance in fast mobile channels.}
\end{figure}



\section{Rate Adaptation Results}
\topheading{SISO Performance.} We first examine the performance of ESNR for SISO rates. \figref{fig:siso_rate_time_opt_eff} shows the rate over time for ESNR and OPT over our trace. The performance metric is the average rate over an interval because each algorithm gets an opportunity to send a packet at the same point in the trace. The rate is averaged over a window of 100 packets to smooth the data for readability. ESNR performs excellently. It is below OPT but consistently overlaps Previous-OPT, which is an upper bound for schemes that track the channel and do not predict the future. ESNR is accurate on 75\% of packets, with the expected 10\% target over-selection.

\figref{fig:siso_rate_skip_opt_eff} shows the effects of mobility on SISO channels. Each line plots the average rate as a function of the speed at which we play the trace. We cover a large range of speeds to show trends, in doubling increments from 1$\times$ (walking speed, $\approx$3\mph) to 128$\times$ ($>$300\mph). All schemes fall off with increased speed, and the gap between OPT and Previous-OPT grows from 20\% at human speeds to 1/3 at the fastest speeds. However, even in these mobile channels, ESNR holds up very well and tracks Previous-OPT within 10\%.
Note that packet SNR was observed to fare quite poorly~\cite{Vutukuru_SoftRate} in mobile channels, but since effective SNR reflects actual link quality its estimates are more accurate (\secref{sec:delivery}) and stable (2--3$\times$ less variance).
%Note this is much better than trained SNR techniques~\cite{Vutukuru_SoftRate}, because packet SNR primarily reflects strong subcarriers, while effective SNR reflects actual performance and is hence more stable.

\heading{SISO Comparison.}
Next, we compare ESNR with SampleRate and SoftRate %. The corresponding rate versus time and rate versus mobility speedup graphs are shown 
in \figref{fig:siso_rate_time_opt_eff_sr_so} and \figref{fig:siso_rate_skip_opt_eff_sr_so}. While it is hard to separate the lines on the graph, at 1$\times$ speed, ESNR slightly outperforms SampleRate which slightly outperforms SoftRate. These results surprised us: SampleRate performs better than we expected, and SoftRate performs less well. 

SampleRate's lagging channel estimate makes it degrade fastest with increasing mobility. However, it maintains a 10--25\% margin with ESNR, still performing well even with large speedups. In deeper analysis, we discovered that dropping rate on retry is an important factor that gives it short-term adaptability. Without this rate fallback (the ``SampleRate fixed'' line), it loses 25--50\% of its performance.

SoftRate has among the slowest falloff with mobility speedup because it directly and accurately measures the channel, and performs the best at maximum speed. However, at slow speeds it is slightly slower on average than SampleRate, though it easily beats a SampleRate without fallback that was the basis for earlier comparisons.\footnote{M. Vutukuru, personal communication, and code inspection.}
We do not believe this gap is fundamental, as SoftRate's post-decoding BER estimate should match or even slightly improve on ESNR\@. Further tuning will likely improve SoftRate. Note that the task for SoftRate is harder in our setting than in the original evaluation. We have added QAM-64 and other coding rates, so it must now chose among 8 SISO rates.

Finally, while the performance differences between schemes are significant, they are always less than a factor of two (ignoring OPT). To put this in perspective, note that other evaluations have reported throughput based on TCP traffic, which will magnify performance gaps by reacting to packet loss.


\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=120 68 491 760,clip,width=0.95\columnwidth]{figures/esnr/siso_rate_time_opt_eff_sr_so.pdf}
      \vspace{-2pt}
      \caption{\label{fig:siso_rate_time_opt_eff_sr_so} ESNR, SampleRate, and SoftRate SISO performance in human-speed mobility.}
      \vspace{-2pt}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=120 68 491 760,clip,width=0.95\columnwidth]{figures/esnr/siso_rate_skip_opt_eff_sr_so.pdf}
      \vspace{-2pt}
      \caption{\label{fig:siso_rate_skip_opt_eff_sr_so} OPT, ESNR, SampleRate, and SoftRate SISO performance in fast mobile channels.}
      \vspace{-2pt}
\end{figure}


\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=125 68 491 760,clip,width=.95\columnwidth]{figures/esnr/mimo_skip_time.pdf}
      \vspace{-2pt}
      \caption{\label{fig:mimo_eff_snr_time} OPT and ESNR MIMO performance in human-speed mobility.}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[angle=-90,viewport=125 68 491 760,clip,width=.95\columnwidth]{figures/esnr/mimo_rate_skip.pdf}
      \vspace{-2pt}
      \caption{\label{fig:mimo_eff_snr_speedup} OPT and ESNR MIMO performance in faster mobile channels.}
      \vspace{-2pt}
\end{figure}

\heading{MIMO Performance.}
To show the generality of our model, Figures~\ref{fig:mimo_eff_snr_time} and \ref{fig:mimo_eff_snr_speedup} show the performance of an unmodified ESNR algorithm running for 802.11n MIMO rates. These results do not include SampleRate or SoftRate as they are SISO schemes. Instead, we use OPT as our benchmark.
%\figref{fig:mimo_eff_snr_time} and \figref{fig:mimo_eff_snr_speedup} show the rate versus time and rate versus speedup graphs. 
These figures are in the same form as for SISO, except the range of rates has grown by a factor of 3 to support up to 195\Mbps. 

The trends in these graphs are similar to those in the SISO graphs: at human mobility speeds, ESNR tracks Previous-OPT and delivers excellent performance, with 80\% accuracy and 10\% over-selection. In faster mobile channels, there is a slightly larger gap with Previous-OPT for MIMO than for SISO, likely because ESNR must now choose between 24 rates instead of 8. It is more likely to choose rates under the highest rate that would have worked. 

Finally, note that with 3 antennas there are only four two- and three-stream rates over 117\Mbps (130, 156, 175.5 and 195 Mbps). The visible gap between indices 25--50 in \figref{fig:mimo_eff_snr_time} reflects only the difference between 1 or 2 rates of potentially different antenna modes. Taken together, these results imply that ESNR's MIMO performance is highly competitive.


\heading{Enhancements.}
One strength of our model is that it can accommodate choices other than rates. This lets us add other functionality to ESNR without increasing complexity. We demonstrated an example enhancement to trim excess transmit power in \secref{sec:delivery}.
% Our example in \secref{sec:delivery} showed that our model has sufficient predictive power to do this. 

A second enhancement is to select the best transmit antenna when there are spare antennas. %A common scenario is an 802.11n AP sending to an 802.11a/g client. The
An 802.11n AP can select antennas to use to send packets to a legacy 802.11a/g client (plus use all antennas to receive packets). With three antennas to choose from, the expected gain in SNR is a little over 2.5\dB~\cite{Goldsmith}. This is often enough to advance to a higher rate.

We ran a version of SISO ESNR that chose the antenna with the highest ESNR for the next transmission. This gave a gain in the average rate of 5\%.  For comparison, OPT achieved a 10\% increase by always knowing which antenna was best. No other rate adaptation schemes directly support these enhancements.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ifx\mainfile\undefined
\input{chapter_tail}
\fi
